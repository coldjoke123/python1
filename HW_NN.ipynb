{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW NN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/coldjoke123/python1/blob/master/HW_NN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "UlyZZHMih0S8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import mnist\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KNrzjjRtiVqP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 載入資料並且重新調整資料的樣子"
      ]
    },
    {
      "metadata": {
        "id": "Emmkq2AZiFv5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train.reshape(60000,784)\n",
        "x_test = x_test.reshape(10000,784)\n",
        "y_train = np_utils.to_categorical(y_train,10)\n",
        "y_test = np_utils.to_categorical(y_test,10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wiU5BZMsvIGo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 將老師上課的模型匯入"
      ]
    },
    {
      "metadata": {
        "id": "ILKIp990iGCW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.optimizers import SGD"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "89cjYcOmvPqu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "1bbfdada-9a22-4350-e148-963825a3bd7b"
      },
      "cell_type": "code",
      "source": [
        "model_old = Sequential()\n",
        "model_old.add(Dense(4, input_dim = 784))\n",
        "model_old.add(Activation('sigmoid'))\n",
        "model_old.add(Dense(2))\n",
        "model_old.add(Activation('sigmoid'))\n",
        "model_old.add(Dense(10))\n",
        "model_old.add(Activation('softmax'))\n",
        "model_old.compile(loss = 'mse', optimizer=SGD(lr = 0.087), metrics=['accuracy'])\n",
        "model_old.summary()"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_3394 (Dense)           (None, 4)                 3140      \n",
            "_________________________________________________________________\n",
            "activation_3394 (Activation) (None, 4)                 0         \n",
            "_________________________________________________________________\n",
            "dense_3395 (Dense)           (None, 2)                 10        \n",
            "_________________________________________________________________\n",
            "activation_3395 (Activation) (None, 2)                 0         \n",
            "_________________________________________________________________\n",
            "dense_3396 (Dense)           (None, 10)                30        \n",
            "_________________________________________________________________\n",
            "activation_3396 (Activation) (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 3,180\n",
            "Trainable params: 3,180\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nM20M7rsvoza",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "outputId": "26bf32d0-736e-40f0-b25e-ed7722031be3"
      },
      "cell_type": "code",
      "source": [
        "model_old_20 = model_old.fit(x_train, y_train, \n",
        "                         batch_size=100, \n",
        "                         epochs=20,\n",
        "                         verbose=1,\n",
        "                         validation_data=(x_test, y_test))"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "60000/60000 [==============================] - 54s 904us/step - loss: 0.0899 - acc: 0.1022 - val_loss: 0.0895 - val_acc: 0.1010\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 16s 259us/step - loss: 0.0893 - acc: 0.1022 - val_loss: 0.0891 - val_acc: 0.1010\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 16s 261us/step - loss: 0.0889 - acc: 0.1468 - val_loss: 0.0888 - val_acc: 0.1783\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 16s 262us/step - loss: 0.0887 - acc: 0.1851 - val_loss: 0.0885 - val_acc: 0.1916\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 16s 259us/step - loss: 0.0884 - acc: 0.1975 - val_loss: 0.0883 - val_acc: 0.1987\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 16s 260us/step - loss: 0.0883 - acc: 0.2015 - val_loss: 0.0882 - val_acc: 0.2017\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 16s 261us/step - loss: 0.0881 - acc: 0.1992 - val_loss: 0.0880 - val_acc: 0.1989\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 16s 261us/step - loss: 0.0879 - acc: 0.2049 - val_loss: 0.0878 - val_acc: 0.2046\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 16s 261us/step - loss: 0.0878 - acc: 0.2053 - val_loss: 0.0877 - val_acc: 0.2038\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 16s 261us/step - loss: 0.0876 - acc: 0.2048 - val_loss: 0.0876 - val_acc: 0.2016\n",
            "Epoch 11/20\n",
            "60000/60000 [==============================] - 16s 264us/step - loss: 0.0875 - acc: 0.2025 - val_loss: 0.0874 - val_acc: 0.2004\n",
            "Epoch 12/20\n",
            "60000/60000 [==============================] - 16s 261us/step - loss: 0.0873 - acc: 0.2022 - val_loss: 0.0873 - val_acc: 0.1999\n",
            "Epoch 13/20\n",
            "60000/60000 [==============================] - 16s 260us/step - loss: 0.0872 - acc: 0.2040 - val_loss: 0.0871 - val_acc: 0.2071\n",
            "Epoch 14/20\n",
            "60000/60000 [==============================] - 16s 260us/step - loss: 0.0870 - acc: 0.2082 - val_loss: 0.0870 - val_acc: 0.2079\n",
            "Epoch 15/20\n",
            "60000/60000 [==============================] - 16s 260us/step - loss: 0.0869 - acc: 0.2088 - val_loss: 0.0868 - val_acc: 0.2079\n",
            "Epoch 16/20\n",
            "60000/60000 [==============================] - 16s 262us/step - loss: 0.0868 - acc: 0.2064 - val_loss: 0.0867 - val_acc: 0.2035\n",
            "Epoch 17/20\n",
            "60000/60000 [==============================] - 16s 267us/step - loss: 0.0866 - acc: 0.2049 - val_loss: 0.0866 - val_acc: 0.2036\n",
            "Epoch 18/20\n",
            "60000/60000 [==============================] - 16s 264us/step - loss: 0.0865 - acc: 0.2043 - val_loss: 0.0864 - val_acc: 0.2041\n",
            "Epoch 19/20\n",
            "60000/60000 [==============================] - 16s 262us/step - loss: 0.0863 - acc: 0.1997 - val_loss: 0.0863 - val_acc: 0.1933\n",
            "Epoch 20/20\n",
            "60000/60000 [==============================] - 16s 261us/step - loss: 0.0862 - acc: 0.1957 - val_loss: 0.0861 - val_acc: 0.1927\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gZ-ZBD9sio0g",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 對資料做正規化，將資料調整至 $[0,1]$ 區間\n",
        "\n",
        "降低資料受到極值的影響"
      ]
    },
    {
      "metadata": {
        "id": "dL3itLxOirs1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train_reg = (x_train - x_train.min())/(x_train.max() - x_train.min())\n",
        "x_test_reg = (x_test - x_test.min())/(x_test.max() - x_test.min())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W-dhtrzvjVOj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 首先，我們增加神經元的個數至每層100個，其餘參數不變"
      ]
    },
    {
      "metadata": {
        "id": "iNDYk7bXiGFX",
        "colab_type": "code",
        "outputId": "81da7de7-da9b-4f30-aefc-130c8eba88b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "cell_type": "code",
      "source": [
        "model_test1 = Sequential()\n",
        "model_test1.add(Dense(100, input_dim = 784))\n",
        "model_test1.add(Activation('sigmoid'))\n",
        "model_test1.add(Dense(100))\n",
        "model_test1.add(Activation('sigmoid'))\n",
        "model_test1.add(Dense(10))\n",
        "model_test1.add(Activation('softmax'))\n",
        "model_test1.compile(loss = 'mse', optimizer=SGD(lr = 0.087), metrics=['accuracy'])\n",
        "model_test1.summary()"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_2533 (Dense)           (None, 100)               78500     \n",
            "_________________________________________________________________\n",
            "activation_2533 (Activation) (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_2534 (Dense)           (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "activation_2534 (Activation) (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_2535 (Dense)           (None, 10)                1010      \n",
            "_________________________________________________________________\n",
            "activation_2535 (Activation) (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 89,610\n",
            "Trainable params: 89,610\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sFOf_V_wiGH_",
        "colab_type": "code",
        "outputId": "226ae074-1c18-44c7-8994-a261a78581c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        }
      },
      "cell_type": "code",
      "source": [
        "model_test1_20 = model_test1.fit(x_train_reg, y_train, \n",
        "                         batch_size=100, \n",
        "                         epochs=20,\n",
        "                         verbose=1,\n",
        "                         validation_data=(x_test_reg, y_test))"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "60000/60000 [==============================] - 29s 490us/step - loss: 0.0902 - acc: 0.1039 - val_loss: 0.0899 - val_acc: 0.1142\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 0.0898 - acc: 0.1131 - val_loss: 0.0897 - val_acc: 0.1137\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 7s 123us/step - loss: 0.0896 - acc: 0.1143 - val_loss: 0.0895 - val_acc: 0.1158\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 7s 121us/step - loss: 0.0894 - acc: 0.1239 - val_loss: 0.0893 - val_acc: 0.1416\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 7s 121us/step - loss: 0.0892 - acc: 0.1467 - val_loss: 0.0891 - val_acc: 0.1456\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 8s 126us/step - loss: 0.0890 - acc: 0.1691 - val_loss: 0.0888 - val_acc: 0.1756\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 7s 119us/step - loss: 0.0887 - acc: 0.1943 - val_loss: 0.0886 - val_acc: 0.2723\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 8s 128us/step - loss: 0.0884 - acc: 0.2507 - val_loss: 0.0883 - val_acc: 0.2283\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 8s 125us/step - loss: 0.0881 - acc: 0.2522 - val_loss: 0.0879 - val_acc: 0.2814\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 7s 119us/step - loss: 0.0878 - acc: 0.2793 - val_loss: 0.0875 - val_acc: 0.3082\n",
            "Epoch 11/20\n",
            "60000/60000 [==============================] - 7s 121us/step - loss: 0.0874 - acc: 0.2983 - val_loss: 0.0871 - val_acc: 0.3072\n",
            "Epoch 12/20\n",
            "60000/60000 [==============================] - 7s 123us/step - loss: 0.0869 - acc: 0.3034 - val_loss: 0.0865 - val_acc: 0.3245\n",
            "Epoch 13/20\n",
            "60000/60000 [==============================] - 8s 125us/step - loss: 0.0863 - acc: 0.3146 - val_loss: 0.0859 - val_acc: 0.3253\n",
            "Epoch 14/20\n",
            "60000/60000 [==============================] - 8s 131us/step - loss: 0.0855 - acc: 0.3194 - val_loss: 0.0850 - val_acc: 0.3271\n",
            "Epoch 15/20\n",
            "60000/60000 [==============================] - 8s 132us/step - loss: 0.0846 - acc: 0.3231 - val_loss: 0.0840 - val_acc: 0.3357\n",
            "Epoch 16/20\n",
            "60000/60000 [==============================] - 6s 98us/step - loss: 0.0835 - acc: 0.3301 - val_loss: 0.0826 - val_acc: 0.3420\n",
            "Epoch 17/20\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 0.0820 - acc: 0.3392 - val_loss: 0.0811 - val_acc: 0.3533\n",
            "Epoch 18/20\n",
            "60000/60000 [==============================] - 7s 124us/step - loss: 0.0803 - acc: 0.3553 - val_loss: 0.0792 - val_acc: 0.3569\n",
            "Epoch 19/20\n",
            "60000/60000 [==============================] - 7s 125us/step - loss: 0.0785 - acc: 0.3718 - val_loss: 0.0773 - val_acc: 0.3767\n",
            "Epoch 20/20\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 0.0765 - acc: 0.3990 - val_loss: 0.0753 - val_acc: 0.4022\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ld8CNENM0RD_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "01c69670-04f0-492f-cf2f-cd539705fc62"
      },
      "cell_type": "code",
      "source": [
        "score = model_test1.evaluate(x_test_reg, y_test)\n",
        "print('loss:', score[0])\n",
        "print('accuracy:', score[1])"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 2s 236us/step\n",
            "loss: 0.07528994209766388\n",
            "accuracy: 0.4022\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rrNPgtVMzym_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 相較於老師上課的模型，可以發現增加神經元數是能增加準確率的！\n",
        "\n",
        "## 於是，在Hidden layer有兩層activation function是sigmoid，loss function是mse，optimizer是SGD的條件下，測試神經元的個數以50個為單位從100到800來尋找準確率最高的組合。"
      ]
    },
    {
      "metadata": {
        "id": "eGgb4J8Y0C35",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def seek_opt(n):\n",
        "    seek_accu = np.zeros((2*(n-1),n-1))\n",
        "    for i in range(1,n):\n",
        "        for j in range(1,n):\n",
        "            model = Sequential()\n",
        "            model.add(Dense(50*(i+1), input_dim = 784))\n",
        "            model.add(Activation('sigmoid'))\n",
        "            model.add(Dense(50*(j+1)))\n",
        "            model.add(Activation('sigmoid'))\n",
        "            model.add(Dense(10))\n",
        "            model.add(Activation('softmax'))\n",
        "            model.compile(loss = 'mse', optimizer=SGD(lr = 0.087), metrics=['accuracy'])\n",
        "            score = model.evaluate(x_test_reg, y_test)\n",
        "            seek_accu[i-1,j-1] = score[1]\n",
        "            seek_accu[i-1+(n-1),j-1] = score[0]\n",
        "    return seek_accu"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7Ka8SYth0C9P",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "seek_accu = seek_opt(16)\n",
        "accu = seek_accu[:16,:]\n",
        "loss = seek_accu[16:,:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pW8VJKoY0DUg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "opt_acc_value = accu.max()\n",
        "opt_acc_index = accu.argmax()\n",
        "\n",
        "model_best = Sequential()\n",
        "model_best.add(Dense(50*((opt_acc_index//15)+2), input_dim = 784))\n",
        "model_best.add(Activation('sigmoid'))\n",
        "model_best.add(Dense(50*((opt_acc_index%15)+2))\n",
        "model_best.add(Activation('sigmoid'))\n",
        "model_best.add(Dense(10))\n",
        "model_best.add(Activation('softmax'))\n",
        "model_best.compile(loss = 'mse', optimizer=SGD(lr = 0.087), metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7VXamWxHv6yx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_best_20 = model_best.fit(x_train_reg, y_train,\n",
        "                         batch_size = 100,\n",
        "                         epochs = 20,\n",
        "                         verbose = 1,\n",
        "                         validation_data = (x_test_reg, y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Za9Qce87pzYA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 由以上結果可知，在兩層hidden layer下，神經元個數分別為 跟 會有最高的準確率！\n",
        "\n",
        "## 比較新的模型與老師上課的模型"
      ]
    },
    {
      "metadata": {
        "id": "hKYfYQIC0DXF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.plot(model_old_20.history[\"acc\"])\n",
        "plt.plot(model_best_20.history[\"acc\"])\n",
        "         \n",
        "plt.title(\"model training accuracy\")\n",
        "plt.ylabel(\"accuracy\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.legend([\"model_old\",\"model_best\"], loc = 'best')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Dk96VUlOr-zX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.plot(model_old_20.history[\"val_loss\"])\n",
        "plt.plot(model_best_20.history[\"val_loss\"])\n",
        "         \n",
        "plt.title(\"model validation loss\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.legend([\"model_old\",\"model_best\"], loc = 'best')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Osi8TE-0wyrK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 在這個參數的基礎下去選擇不同的loss function 與activation function做測試"
      ]
    },
    {
      "metadata": {
        "id": "FQUjiUWDwi5T",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}